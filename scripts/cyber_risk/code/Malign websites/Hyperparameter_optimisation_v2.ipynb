{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d99e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "df=pd.read_csv(r'C:\\Users\\isarachchand\\\\Documents\\git\\apf\\datasets\\cyber_risk\\data\\malign_websites_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b293d465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL -> 1781\n",
      "CHARSET -> 9\n",
      "SERVER -> 239\n",
      "WHOIS_COUNTRY -> 49\n",
      "WHOIS_STATEPRO -> 182\n",
      "WHOIS_REGDATE -> 891\n",
      "WHOIS_UPDATED_DATE -> 594\n"
     ]
    }
   ],
   "source": [
    "#Prep the data\n",
    "\n",
    "100 * df['Type'].value_counts()/len(df)   #variable imbalance\n",
    "\n",
    "#unique categories for each categorical column\n",
    "\n",
    "for i in df.select_dtypes(include='object').columns:\n",
    "    print(f\"{i} -> {df[i].nunique()}\")\n",
    "    \n",
    "df['CHARSET'].value_counts()\n",
    "\n",
    "# Top 5 categories kept\n",
    "\n",
    "def CHARSET_CLEANER(x):\n",
    "    if x not in ['UTF-8','ISO-8859-1','utf-8','us-ascii','iso-8859-1']:\n",
    "        return \"OTHERS\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df['CHARSET'] = df['CHARSET'].apply(CHARSET_CLEANER)\n",
    "df['CHARSET'].value_counts()\n",
    "df['SERVER'].value_counts()\n",
    "\n",
    "# Top 5 categories kept\n",
    "\n",
    "def SERVER_CLEANER(x):\n",
    "    if x not in ['Apache','nginx','None','Microsoft-HTTPAPI/2.0','cloudflare-nginx']:\n",
    "        return \"OTHERS\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df['SERVER'] = df['SERVER'].apply(SERVER_CLEANER)\n",
    "df['SERVER'].value_counts()\n",
    "df['WHOIS_STATEPRO'].value_counts()[:11]\n",
    "\n",
    "def STATE_CLEANER(x):\n",
    "    if x not in ['CA','None','NY','WA','Barcelona','FL']:\n",
    "        return \"OTHERS\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df['WHOIS_STATEPRO'] = df['WHOIS_STATEPRO'].apply(STATE_CLEANER)\n",
    "df['WHOIS_STATEPRO'].value_counts()\n",
    "\n",
    "def DATE_CLEANER(x):\n",
    "    if x == 'None':\n",
    "        return \"Absent\"\n",
    "    else:\n",
    "        return \"Present\"\n",
    "df['WHOIS_REGDATE'] = df['WHOIS_REGDATE'].apply(DATE_CLEANER)\n",
    "df['WHOIS_UPDATED_DATE'] = df['WHOIS_UPDATED_DATE'].apply(DATE_CLEANER)\n",
    "\n",
    "df.drop(['URL','WHOIS_COUNTRY','CONTENT_LENGTH'],axis=1,inplace=True)\n",
    "# change null values to 0\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in ['CHARSET','SERVER', 'WHOIS_STATEPRO', 'WHOIS_REGDATE', 'WHOIS_UPDATED_DATE']:\n",
    "    df[column] = le.fit_transform(df[column].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536241f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['Random Forest', 'XGB Classifier', 'K Nearest Neighbour', 'Decision Tree']\n",
    "accuracy_list = []\n",
    "train_accuracy_list = []\n",
    "train_acc_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "f1_score_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a172c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "y = df['Type']\n",
    "X = df.drop('Type', axis=1)\n",
    "\n",
    "# Split data\n",
    "y = df['Type']\n",
    "X = df.drop('Type', axis=1)\n",
    "\n",
    "best_index = 1\n",
    "partition_count = 5\n",
    "\n",
    "# get train test split\n",
    "partition_size = math.ceil(len(X) / partition_count)\n",
    "test_start = best_index * partition_size\n",
    "test_end = test_start + partition_size\n",
    "test_x = X[test_start:test_end]\n",
    "test_y = y[test_start:test_end]\n",
    "train_x = pd.concat([X[:test_start],X[test_end:]])\n",
    "train_y =  pd.concat([y[:test_start], y[test_end:]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d3ffcd",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3156d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: -0.7647058823529412]\n",
      "Best hyperparameters are: {'max_depth': 111.0, 'max_features': 4.387342497187583, 'min_samples_leaf': 2.0770919480139733, 'min_samples_split': 2.3553702014514015, 'n_estimators': 413.4884362317157}\n"
     ]
    }
   ],
   "source": [
    "space={'max_depth': hp.quniform(\"max_depth\", 10, 180, 1), # 120, 180\n",
    "        'min_sample_leaf' : hp.uniform('min_samples_leaf',1,5),\n",
    "        'min_samples_split':hp.uniform('min_samples_split',2,6),\n",
    "        'n_estimators': hp.uniform('n_estimators', 200, 900),\n",
    "       'max_features': hp.uniform('max_features', 1, 5)\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=int(space['n_estimators']), max_depth=int(space['max_depth']),\n",
    "        min_samples_split=int(space['min_samples_split']),\n",
    "        min_samples_leaf=int(space['min_sample_leaf']),\n",
    "        max_features=int(space['max_features']), random_state=2)\n",
    "\n",
    "    clf.fit(train_x, train_y)\n",
    "    pred = clf.predict(test_x)\n",
    "    \n",
    "    #training accuracy\n",
    "    y_train_pred = clf.predict(train_x)\n",
    "    \n",
    "    #calculate metrics\n",
    "    f1s = f1_score(pred, test_y)\n",
    "\n",
    "    return {'loss': -f1s, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"Best hyperparameters are: {}\".format(best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa7a295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9551820728291317\n",
      "Training accuracy 0.9915730337078652\n",
      "Recall :  0.8154908922506947\n",
      "Precision :  0.9587542087542087\n",
      "F1 Score :  0.8699690402476781\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "best_model = RandomForestClassifier(n_estimators=int(best_hyperparams['n_estimators']),\n",
    "                                    max_depth=int(best_hyperparams['max_depth']),\n",
    "                                    min_samples_split=int(best_hyperparams['min_samples_split']),\n",
    "                                    min_samples_leaf=int(best_hyperparams['min_samples_leaf']),\n",
    "                                    max_features=int(best_hyperparams['max_features']), random_state=2)\n",
    "\n",
    "\n",
    "best_model.fit(train_x, train_y)\n",
    "\n",
    "y_train_pred = best_model.predict(train_x)\n",
    "y_test_pred = best_model.predict(test_x)\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_pred, train_y)\n",
    "accuracy = accuracy_score(y_test_pred, test_y)\n",
    "recall = recall_score(test_y, y_test_pred, average='macro')\n",
    "precision = precision_score(test_y, y_test_pred, average='macro')\n",
    "f1score = f1_score(test_y, y_test_pred, average='macro')\n",
    "\n",
    "accuracy_list.append(accuracy)\n",
    "recall_list.append(recall)\n",
    "precision_list.append(precision)\n",
    "f1_score_list.append(f1score)\n",
    "train_acc_list.append(train_accuracy)\n",
    "\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Training accuracy\", train_accuracy)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"Precision : \", precision)\n",
    "print(\"F1 Score : \", f1score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722f959",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7871dc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.89trial/s, best loss: -0.8450704225352113]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'gamma': 4.082224695979065, 'max_depth': 142.0, 'n_estimators': 893.4900161366173}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "space2={'max_depth': hp.quniform(\"max_depth\", 10, 180, 1), # 120, 180\n",
    "        'gamma': hp.uniform ('gamma', 1,25),\n",
    "        #'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        #'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        #'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        #'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': hp.uniform('n_estimators', 200, 900), # 100, 200, 300\n",
    "        #\"n_estimators\": hp.quniform('n_estimators', 100,200,1),\n",
    "        #'seed': 0\n",
    "    }\n",
    "\n",
    "\n",
    "def objective2(space2):\n",
    "    clf_model = xgb.XGBClassifier(\n",
    "        n_estimators=int(space2['n_estimators']), gamma=space2['gamma'], max_depth=int(space2['max_depth']), random_state=2)\n",
    "\n",
    "    evaluation = [(train_x, train_y), (test_x, test_y)]\n",
    "\n",
    "    clf_model.fit(train_x, train_y,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "    pred = clf_model.predict(test_x)\n",
    "    f1s = f1_score(pred, test_y)\n",
    "\n",
    "    return {'loss': -f1s, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials2 = Trials()\n",
    "\n",
    "best_hyperparams2 = fmin(fn = objective2,\n",
    "                        space = space2,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials2)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844a8525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.957983193277311\n",
      "Train accuracy:  0.9824438202247191\n",
      "Recall :  0.8489117011423278\n",
      "Precision :  0.9346634615384615\n",
      "F1 Score :  0.8855598059538821\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "best_model = xgb.XGBClassifier(n_estimators=int(best_hyperparams2['n_estimators']),\n",
    "                           gamma=best_hyperparams2['gamma'],\n",
    "                           max_depth=int(best_hyperparams2['max_depth']), random_state=2)\n",
    "\n",
    "\n",
    "best_model.fit(train_x, train_y)\n",
    "\n",
    "y_train_pred = best_model.predict(train_x)\n",
    "y_test_pred = best_model.predict(test_x)\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_pred, train_y)\n",
    "accuracy = accuracy_score(y_test_pred, test_y)\n",
    "recall = recall_score(test_y, y_test_pred, average='macro')\n",
    "precision = precision_score(test_y, y_test_pred, average='macro')\n",
    "f1score = f1_score(test_y, y_test_pred, average='macro')\n",
    "\n",
    "accuracy_list.append(accuracy)\n",
    "recall_list.append(recall)\n",
    "precision_list.append(precision)\n",
    "f1_score_list.append(f1score)\n",
    "train_acc_list.append(train_accuracy)\n",
    "\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"Precision : \", precision)\n",
    "print(\"F1 Score : \", f1score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47cd95",
   "metadata": {},
   "source": [
    "## K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61ed211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 40.12trial/s, best loss: -0.676056338028169]\n",
      "Best hyperparameters are: {'n_neighbors': 1.0541818310979505}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "spaceknn={'n_neighbors': hp.uniform('n_neighbors', 1,100)}\n",
    "\n",
    "def objective(spaceknn):\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=int(spaceknn['n_neighbors']))\n",
    "        \n",
    "    clf.fit(train_x, train_y)\n",
    "    pred = clf.predict(test_x)\n",
    "\n",
    "    f1s = f1_score(pred, test_y)\n",
    "\n",
    "    return {'loss': -f1s, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = spaceknn,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"Best hyperparameters are: {}\".format(best_hyperparams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb307c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9355742296918768\n",
      "Train accuracy:  1.0\n",
      "Recall :  0.7831892559431923\n",
      "Precision :  0.8740061162079511\n",
      "F1 Score :  0.820143254550632\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "best_model = KNeighborsClassifier(n_neighbors=int(best_hyperparams['n_neighbors']))\n",
    "\n",
    "\n",
    "best_model.fit(train_x, train_y)\n",
    "\n",
    "y_train_pred = best_model.predict(train_x)\n",
    "y_test_pred = best_model.predict(test_x)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_pred, train_y)\n",
    "accuracy = accuracy_score(y_test_pred, test_y)\n",
    "recall = recall_score(test_y, y_test_pred, average='macro')\n",
    "precision = precision_score(test_y, y_test_pred, average='macro')\n",
    "f1score = f1_score(test_y, y_test_pred, average='macro')\n",
    "\n",
    "accuracy_list.append(accuracy)\n",
    "recall_list.append(recall)\n",
    "precision_list.append(precision)\n",
    "f1_score_list.append(f1score)\n",
    "train_acc_list.append(train_accuracy)\n",
    "\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"Precision : \", precision)\n",
    "print(\"F1 Score : \", f1score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946257ae",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9345153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 96.89trial/s, best loss: -0.8848572810836962]\n",
      "Best hyperparameters are: {'criterion': 1, 'max_depth': 9, 'max_features': 3, 'min_samples_leaf': 1.476267608793267, 'min_samples_split': 5.3783066173675005}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "space4dt = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "    'min_samples_leaf' : hp.uniform('min_samples_leaf',1,5),\n",
    "    'min_samples_split':hp.uniform('min_samples_split',2,6),\n",
    "    \n",
    "}\n",
    "\n",
    "def objective(space4dt):\n",
    "    clf = DecisionTreeClassifier(\n",
    "        max_depth=int(space4dt['max_depth']),\n",
    "        max_features=space4dt['max_features'],\n",
    "        min_samples_split=int(space4dt['min_samples_split']),\n",
    "        min_samples_leaf=int(space4dt['min_samples_leaf']),\n",
    "        criterion=space4dt['criterion'],\n",
    "        random_state=2)\n",
    "\n",
    "    clf.fit(train_x, train_y)\n",
    "    pred = clf.predict(test_x)\n",
    "\n",
    "    f1s = f1_score(test_y, pred, average='macro')\n",
    "\n",
    "    return {'loss': -f1s, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space4dt,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"Best hyperparameters are: {}\".format(best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4fa2ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9215686274509803\n",
      "Train accuracy:  0.9726123595505618\n",
      "Recall :  0.7540521765977153\n",
      "Precision :  0.8256976053829408\n",
      "F1 Score :  0.7837487019730011\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "\n",
    "best_model = DecisionTreeClassifier(max_depth=int(best_hyperparams['max_depth']),\n",
    "                                    max_features=best_hyperparams['max_features'],\n",
    "                                    min_samples_split=int(best_hyperparams['min_samples_split']),\n",
    "                                    min_samples_leaf=int(best_hyperparams['min_samples_leaf']),\n",
    "                                    random_state=2)\n",
    "#criterion=best_hyperparams['criterion'],\n",
    "\n",
    "best_model.fit(train_x, train_y)\n",
    "\n",
    "y_train_pred = best_model.predict(train_x)\n",
    "y_test_pred = best_model.predict(test_x)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_pred, train_y)\n",
    "accuracy = accuracy_score(y_test_pred, test_y)\n",
    "recall = recall_score(test_y, y_test_pred, average='macro')\n",
    "precision = precision_score(test_y, y_test_pred, average='macro')\n",
    "f1score = f1_score(test_y, y_test_pred, average='macro')\n",
    "\n",
    "accuracy_list.append(accuracy)\n",
    "recall_list.append(recall)\n",
    "precision_list.append(precision)\n",
    "f1_score_list.append(f1score)\n",
    "train_acc_list.append(train_accuracy)\n",
    "\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"Precision : \", precision)\n",
    "print(\"F1 Score : \", f1score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf090d",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a26db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# space4svm = {'C': hp.uniform('C', 0, 20),\n",
    "#     'kernel': hp.choice('kernel', ['linear', 'sigmoid', 'poly', 'rbf']),\n",
    "#     'gamma': hp.uniform('gamma', 0, 20),\n",
    "#     }\n",
    "\n",
    "# def objective(space4svm):\n",
    "    \n",
    "#     clf = SVC(\n",
    "#         C=space4svm['C'], kernel=space4svm['kernel'],\n",
    "#         gamma=int(space4svm['gamma']),\n",
    "#         random_state=2)\n",
    "\n",
    "#     clf.fit(train_x, train_y)\n",
    "#     pred = clf.predict(test_x)\n",
    "\n",
    "#     accuracy = recall_score(test_y, pred, average='macro')\n",
    "    \n",
    "#     print(\"Accuracy: \", accuracy)\n",
    "#     print(\"\\n\")\n",
    "#     return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# trials = Trials()\n",
    "\n",
    "# best_hyperparams = fmin(fn = objective,\n",
    "#                         space = space4svm,\n",
    "#                         algo = tpe.suggest,\n",
    "#                         max_evals = 50,\n",
    "#                         trials = trials)\n",
    "\n",
    "# print(\"Best hyperparameters are: {}\".format(best_hyperparams))\n",
    "# best_acc = min([t['result']['loss'] for t in trials.trials])\n",
    "# accuracy_list.append(-best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986561c",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc68b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# space4lr = {\n",
    "#     'penalty': hp.choice('penalty', ['none', 'l1', 'l2', 'elasticnet']),\n",
    "#     'solver': hp.choice('solver', ['liblinear', 'none']),\n",
    "#     'C': hp.uniform('C', 0, 20)\n",
    "    \n",
    "# }\n",
    "\n",
    "# def objective(space4tlr):\n",
    "\n",
    "#     clf = LogisticRegression(\n",
    "#         penalty=space4lr['penalty'],\n",
    "#         solver=space4lr['solver'], \n",
    "#         C=space4lr['C'],\n",
    "#         random_state=2)\n",
    "\n",
    "#     clf.fit(train_x, train_y)\n",
    "#     pred = clf.predict(test_x)\n",
    "\n",
    "#     accuracy = recall_score(test_y, pred, average='macro')\n",
    "    \n",
    "#     print(\"Accuracy: \", accuracy)\n",
    "#     print(\"\\n\")\n",
    "#     return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# trials = Trials()\n",
    "# best_hyperparams = fmin(fn = objective,\n",
    "#                         space = space4lr,\n",
    "#                         algo = tpe.suggest,\n",
    "#                         max_evals = 200,\n",
    "#                         trials = trials)\n",
    "\n",
    "# print(\"Best hyperparameters are: {}\".format(best_hyperparams))\n",
    "\n",
    "# best_acc = min([t['result']['loss'] for t in trials.trials])\n",
    "# accuracy_list.append(-best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44e5bf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Random Forest', 'XGB Classifier', 'K Nearest Neighbour', 'Decision Tree']\n",
      "[0.9915730337078652, 0.9824438202247191, 1.0, 0.9726123595505618]\n",
      "[0.9551820728291317, 0.957983193277311, 0.9355742296918768, 0.9215686274509803]\n",
      "[0.8154908922506947, 0.8489117011423278, 0.7831892559431923, 0.7540521765977153]\n",
      "[0.9587542087542087, 0.9346634615384615, 0.8740061162079511, 0.8256976053829408]\n",
      "[0.8699690402476781, 0.8855598059538821, 0.820143254550632, 0.7837487019730011]\n"
     ]
    }
   ],
   "source": [
    "print(models_list)\n",
    "print(train_acc_list)\n",
    "print(accuracy_list)\n",
    "print(recall_list)\n",
    "print(precision_list)\n",
    "print(f1_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ffe8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame with accuracies of models\n",
    "\n",
    "model_scores = pd.DataFrame({\n",
    "    'Model Name' : models_list,\n",
    "    'Accuracy' : accuracy_list, \n",
    "    'Training accuracy': train_acc_list,\n",
    "    'Recall' : recall_list, \n",
    "    'Precision' : precision_list, \n",
    "    'F1 Score' : f1_score_list\n",
    "})\n",
    "\n",
    "file_name = r'C:\\Users\\isarachchand\\Documents\\git\\apf\\output\\cyber_risk\\model_accuracies.csv'\n",
    "\n",
    "model_scores.to_csv(file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f0187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
